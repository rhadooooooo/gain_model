
import torch
import torch.nn as nn
import torch.optim as optim
import pandas as pd
import numpy as np

# Activam modul de detectie a operatiilor in-place care pot strica graficul de calcul
torch.autograd.set_detect_anomaly(True)

# =====================
# DEFINIM CLASA GAIN
# =====================
class GAIN(nn.Module):
    def __init__(self, input_dim, hidden_dim):
        super(GAIN, self).__init__()

        # Generatorul primeste date + masca si genereaza completari
        self.generator = nn.Sequential(
            nn.Linear(input_dim * 2, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, input_dim),
            nn.Sigmoid()
        )

        # Discriminatorul primeste date completate si decide ce e real vs. generat
        self.discriminator = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, input_dim),
            nn.Sigmoid()
        )

    def forward(self, x, mask):
        generator_input = torch.cat([x, mask], dim=1) # concateneaza datele cu masca
        generated_data = self.generator(generator_input) # genereaza valori lipsa
        imputed_data = torch.where(mask.bool(), x, generated_data) # pastreaza valorile reale
        return generated_data, imputed_data

# ============================
# NORMALIZARE & DENORMALIZARE
# ============================
def normalize(data):
    X_min = np.nanmin(data, axis=0)
    X_max = np.nanmax(data, axis=0)
    diff = X_max - X_min
    diff[diff == 0] = 1 # evitam impartirea la zero
    return (data - X_min) / diff, X_min, X_max

def denormalize(data, X_min, X_max):
    return data * (X_max - X_min) + X_min

# ================
# INCARCARE DATE
# ================
df = pd.read_csv("diabetes_readmission_NAN.csv") # date cu valori lipsa
mask_df = pd.read_csv("diabetes_readmission_NAN_to_mask.csv") # matrice masca
data_array = df.values.astype(np.float32)
mask_array = mask_df.values.astype(np.float32)
normalized_data, X_min, X_max = normalize(data_array)
normalized_data[np.isnan(normalized_data)] = 0 # inlocuim NaN cu 0

# convertim in tensori PyTorch
data_tensor = torch.tensor(normalized_data, dtype=torch.float32)
mask_tensor = torch.tensor(mask_array, dtype=torch.float32)

# =============
# INITIALIZARE
# =============
input_dim = data_tensor.shape[1]
model = GAIN(input_dim=input_dim, hidden_dim=128)

# Optimizatori pentru generator si discriminator
optimizer_G = optim.Adam(model.generator.parameters(), lr=0.001)
optimizer_D = optim.Adam(model.discriminator.parameters(), lr=0.001)

# =============
# ANTRENARE
# =============
num_epochs = 100
for epoch in range(num_epochs):
    generated_data, imputed_data = model(data_tensor, mask_tensor)  # forward prin model
    inv_mask = 1.0 - mask_tensor # inverseaza masca pentru zonele lipsa

    # ----- DISCRIMINATOR -----
    imputed_for_disc = imputed_data.detach() # decupleaza de la graficul anterior
    disc_output_disc = model.discriminator(imputed_for_disc) # predictii discriminator
    # loss: vrea sa prezica 1 pt. valori reale si 0 pt. completate
    discriminator_loss = torch.mean(mask_tensor * (1 - disc_output_disc) + inv_mask * disc_output_disc)

    optimizer_D.zero_grad()
    discriminator_loss.backward() # backward pass
    optimizer_D.step()

     # ----- GENERATOR -----
    with torch.no_grad():
        _, imputed_for_gen = model(data_tensor, mask_tensor) # refacem forward pt. generator
    imputed_for_gen = imputed_for_gen.detach().clone().requires_grad_(True)

    disc_output_gen = model.discriminator(imputed_for_gen)
    # loss: vrea sa pacaleasca discriminatorul in zonele lipsa
    generator_loss = torch.mean((inv_mask * disc_output_gen - inv_mask * generated_data.detach()) ** 2)

    optimizer_G.zero_grad()
    generator_loss.backward()
    optimizer_G.step()

    print(f"Epoch {epoch+1}: GenLoss = {generator_loss.item():.6f}, DiscLoss = {discriminator_loss.item():.6f}")

# =============
# SALVARE REZULTATE
# =============
final_imputed = imputed_data.detach().numpy()
denormalized = denormalize(final_imputed, X_min, X_max) # aducem inapoi in valori reale
output_df = pd.DataFrame(denormalized, columns=df.columns)
output_df.to_csv("diabetes_readmission_imputed_final_100_epochs.csv", index=False)
print("Model antrenat și fișier salvat!")
